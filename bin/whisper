#!/usr/bin/env bash
set -euo pipefail

# OpenClaw wrapper: keep the old `whisper` command name, but run MLX Whisper.
# We intentionally map only the flags we currently use in OpenClaw.

VENV="/Users/mk/clawd/.venv-mlx-whisper"
MLX="$VENV/bin/mlx_whisper"

if [[ ! -x "$MLX" ]]; then
  echo "mlx_whisper not found at $MLX" >&2
  exit 1
fi

# Defaults
# Prefer MLX Turbo as the default for best speed/quality tradeoff.
MODEL="mlx-community/whisper-turbo"
OUTDIR="."
FORMAT="txt"
LANG=""
TASK=""

ARGS=()

# Parse a minimal subset of openai-whisper CLI flags.
while [[ $# -gt 0 ]]; do
  case "$1" in
    --model)
      MODEL="$2"; shift 2 ;;
    --output_dir)
      OUTDIR="$2"; shift 2 ;;
    --output_format)
      FORMAT="$2"; shift 2 ;;
    --language)
      LANG="$2"; shift 2 ;;
    --task)
      TASK="$2"; shift 2 ;;
    --*)
      # Unknown flag: ignore (for compatibility) but preserve as passthrough if desired later.
      # For now, drop it to avoid breaking on mismatched flags.
      shift 1 ;;
    *)
      ARGS+=("$1"); shift 1 ;;
  esac
done

if [[ ${#ARGS[@]} -lt 1 ]]; then
  echo "Usage: whisper <audio_file> [--model ...] [--output_dir ...] [--output_format ...]" >&2
  exit 2
fi

# Map common OpenAI Whisper model names to MLX community repos
case "$MODEL" in
  turbo)
    MODEL="mlx-community/whisper-turbo" ;;
  tiny|base|small|medium|large|large-v2|large-v3)
    MODEL="mlx-community/whisper-$MODEL" ;;
  *)
    : ;;
esac

CMD=("$MLX" "${ARGS[0]}" --model "$MODEL" -f "$FORMAT" --output-dir "$OUTDIR")

# Try to pass language/task if supported (ignore if mlx_whisper rejects them)
if [[ -n "$LANG" ]]; then
  CMD+=(--language "$LANG")
fi
if [[ -n "$TASK" ]]; then
  CMD+=(--task "$TASK")
fi

# Run
"${CMD[@]}"